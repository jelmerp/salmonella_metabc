---
title: |
  | Methods and QC -- <br> Salmonella project metabarcoding data
pagetitle: "dada_qc"
author: "Jelmer Poelstra (poelstra.1@osu.edu), MCIC Wooster, OSU"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: cerulean
    highlight: kate
    toc: true
    toc_float: true
    fig_caption: true
    anchor_sections: true
    df_print: kable
    css: html_page.css
bibliography: salmonella.bib
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
# nocite: '@*'

knitr::opts_chunk$set(
  echo = FALSE,
  eval = TRUE,
  cache = FALSE,
  warning = FALSE,
  message = FALSE,
  out.width = "85%"
)
knitr::opts_knit$set(root.dir = here::here(),
                     output.dir = here::here("reports/html"))
```

```{r}
## Load packages
if (!"pacman" %in% installed.packages()) install.packages("pacman")
packages <- c("tidyverse", "here",
              "phyloseq",
              "patchwork", "RColorBrewer",
              "DT", "kableExtra")
pacman::p_load(char = packages)
```

```{r}
## Source script with functions
source(here("scripts/report_funs.R"))
```

```{r}
## DATASET-SPECIFIC SETTINGS
asv_minlen <- 245
asv_maxlen <- 260

trt_levels <- c("NC", "L", "S", "L+S", "Water")
trt_cols <- brewer.pal(length(trt_levels), "Set1")
names(trt_cols) <- trt_levels

show_sample_names <- TRUE
```

```{r}
# General settings

## Taxonomic levels
tax_levels <- c("domain", "phylum", "class", "order", "family",
                "genus", "species")

## Plotting order
status_levels <- c("Input", "FASTQ filtered", "Denoised", "Pairs merged",
                   "Non-chimeric", "Length-filtered")
status_levels2 <- c("FASTQ filtering", "Denoising", "Read merging",
                    "Chimera removal", "Length filtering", "(remaining)")

## Plotting theme
theme_set(theme_bw(base_size = 14))
```

```{r}
## Define input files
qc_file <- here("results/dada/qc/nseq_summary.txt")
meta_file <- here("metadata/meta.tsv") # Need the metadata because some samples are not in the final ps object
ps_file <- here("results/phyloseq/ps_dadatax_filt.rds")
```

```{r}
## Read input files
qc_raw <- read_tsv(qc_file) %>%
  rename(sampleID = sample_id) %>% 
  mutate(sampleID = sub("_S\\d+", "", sampleID))

meta <- read_tsv(meta_file) %>%
  mutate(treatment = factor(treatment, levels = trt_levels)) %>% 
  arrange(treatment, sampleID) %>% 
  mutate(sampleID = fct_inorder(sampleID))

ps <- readRDS(ps_file)
```

```{r}
## Vector of samples that passed filtering
smp_pass <- sample_data(ps)$sampleID
```

<br>

----

## Methods

### Summary for manuscript

All code used for the analyses can be found in our GitHub repository
(https://github.com/jelmerp/salmonella_metabc).
After quality control of FASTQ files with `fastqc` (version 0.11.8, @andrews_fastqc_2010)
and `multiqc` (version 1.11, @ewels_multiqc_2016),
primers were removed from each read using `cutadapt` (version 3.4, @martin_cutadapt_2011)
and read pairs for which a primer was not detected either for the forward or reverse
read were removed.

The R/Bioconductor package `DADA2` (version 1.16, @callahan_dada2_2016) was used
to generate a count table with counts of each inferred Amplicon Sequence Variation
(ASV) for each sample
Briefly, this consisted of the following consecutive steps:
sequence quality filtering and trimming (`filterAndTrim()` function),
dereplication (`derepFastq()` function),
sequence error modeling (`learnErrors()` function),
sequence denoising/ASV inference (`dada()` function),
merging forward and reverse read pairs (`mergePairs()` function),
creating a sequence table (`makeSequenceTable()` function),
inferring and removing chimeric ASVs (`removeBimeraDenovo()` function),
and taxonomic assignment (`assignTaxonomy()` and `addSpecies()` functions)
using the Silva (@quast_silva_2013) database
(version 138.1, available at https://zenodo.org/record/4587955).

Next, several filtering steps were performed:
ASVs were filtered by length
(retaining only ASVs with lengths between `r asv_minlen` and `r asv_maxlen` bp),
contaminants were inferred and removed with the R/Bioconductor package `decontam`
(version 1.14.0, @davis_simple_2018) using 4 negative control samples,
ASVs that had been assigned to the order Chloroplast, the family Mitochondria,
or the domain Eukaryota were removed,
and samples with a total ASV count below a 1,000 were removed.

A phylogenetic tree for all ASVs was inferred using the R package `phangorn`
(version 2.8.1, @schliep_phangorn_2011).

### Detailed ASV inference methods

After QC and primer removal from the raw sequences in FASTQ files,
we inferred Amplicon Sequence Variants (ASVs) and performed taxonomic assignments
for ASVs using the steps below.
Unless mentioned otherwise, the functions referenced are from the
R/Bioconductor package `DADA2` (version 1.16,
[Callahan et al. 2016](https://www.nature.com/articles/nmeth.3869))
and were used with default parameters.

1. FASTQ files were filtered and trimmed using the `filterAndTrim()` function
   with parameters `truncLen = c(150, 150)`, `trimLeft = 0`, `trimRight = 0`,
   `maxN = 0`, `maxEE = c(2, 2)`, `truncQ = 2`, and `rm.phix = TRUE`.

2. Sequences from filtered FASTQ files were dereplicated using the `derepFastq()`
   function.

3. Sequencing errors were modeled using the `learnErrors()` function.

4. ASVs were inferred separately for forward and reverse read sets
   using the `dada()` function with the parameter `pool = "pseudo"`.
   This process is also called *denoising*.
   
5. Sequences from forward and reverse reads were merged using the `mergePairs()`
   function.
   
6. An initial ASV count table was created using the `makeSequenceTable()`
   function.
   
7. Chimeric sequences were inferred and removed using the `removeBimeraDenovo()`
   function with the parameter `method = "pool"`.
   
8. ASVs were filtered by length,
   with minimum and maximum permitted sizes of `r asv_minlen` and `r `asv_maxlen`
   bp, respectively.

9. Taxonomy was assigned using the `assignTaxonomy()` function followed by
   the `addSpecies()` function, with the Silva version 138.1 database
   ([file used with `assignTaxonomy()`](https://zenodo.org/record/4587955/files/silva_nr99_v138.1_train_set.fa.gz);
    [file used with `addSpecies()`](https://zenodo.org/record/4587955/files/silva_species_assignment_v138.1.fa.gz).

10. From a FASTA file with ASV sequences,
    ASVs were aligned and a tree was inferred using the R package
    _phangorn_ (version 2.8.1, 
    [Schliep 2011](https://academic.oup.com/bioinformatics/article/27/4/592/198887)).
    Specifically, we used the following sequence of functions:
    `AlignSeqs()`, `dist.ml()`, `NJ()`, `pml()`,
    `update()` (with parameters `k = 4` and `inv = 0.2`),
    and `optim.pml()` (with parameters `model = GTR`, `optInv = TRUE`, and
    `rearrangement = stochastic`).

11. An object of class _phyloseq_ from the R/Bioconductor package _phyloseq_
    (version 1.38.0, [McMurdie & Holmes 2013](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0061217))
    was created from the resulting ASV count table (Step 8),
    taxonomy table (Step 9), tree (Step 10), and the sample metadata.
    
12. ASVs were filtered for contaminants with the R/Bioconductor package _decontam_
    (version 1.14.0, [Davis et al. 2018](https://microbiomejournal.biomedcentral.com/articles/10.1186/s40168-018-0605-2)),
    making use of information from the water negative control samples
    using the `isContaminant()` function with parameters `method = prevalence` and
    `threshold = 0.1`.
    
13. ASVs assigned to the order Chloroplast, the family Mitochondria,
    or the domain Eukaryota were removed.
    
14. Samples with a total ASV count below a 1,000 were removed.


<br>

----

## Samples filtered out

```{r}
failed <- qc_raw %>%
  filter(lenfilter < 1000) %>%
  select(sampleID, input, output = lenfilter)

nfail <- nrow(failed)
```

In step 14,
**`r nfail` samples had fewer than 1,000 total ASVs and were removed.**
Among these, the maximum number of ASVs was in fact as low as
`r max(failed$output)`, so it seems to me that lowering this threshold
to retain more samples is not reasonable.

```{r}
## Table of failed samples by treatment
fail_by_treat <- left_join(failed, meta, by = "sampleID") %>%
  count(treatment, name = "failed samples") %>%
  full_join(count(meta, treatment, name = "total samples"), by = "treatment") %>%
  mutate(`failed samples` = replace_na(`failed samples`, 0)) %>% 
  mutate(`passed samples` = `total samples` - `failed samples`) %>%
  select(treatment, `total samples`, `failed samples`, `passed samples`) %>%
  arrange(treatment)

fail_by_treat %>% make_kable()
```

Failed samples:

```{r, results='asis'}
#failed %>% make_kable()
cat(paste0(failed$sampleID, collapse = ", "))
```

<br>

----

## Read loss along the pipeline

Not shown in the graphs below:

- **Cutadapt results are currently not reported.**
- In step 12, no ASVs were identified as contaminants.
- In step 13, no off-target taxa were detected.

### Read loss for all samples

```{r}
## Process QC file
qc <- qc_raw %>%
  dplyr::rename(Input = input,
                `FASTQ filtered` = filtered,
                Denoised = denoised_r,
                `Pairs merged` = merged,
                `Non-chimeric` = nonchim,
                `Length-filtered` = lenfilter) %>%
  select(-denoised_f)
```

```{r, out.width="95%"}
## Barplot
qc_for_barplot <- qc %>%
  mutate(`FASTQ filtering` = Input - `FASTQ filtered`,
         Denoising = `FASTQ filtered` - Denoised,
         `Read merging` = Denoised - `Pairs merged`,
         `Chimera removal` = `Pairs merged` - `Non-chimeric`,
         `Length filtering` = `Non-chimeric` - `Length-filtered`,
         `(remaining)` = `Length-filtered`) %>%
  select(sampleID, `FASTQ filtering`, Denoising, `Read merging`,
         `Chimera removal`, `Length filtering`, `(remaining)`) %>%
  pivot_longer(cols = -sampleID,
               names_to = "status",
               values_to = "proportion") %>%
  left_join(meta, by = "sampleID") %>%
  arrange(treatment, sampleID) %>% 
  mutate(status = factor(status, levels = status_levels2),
         treatment = factor(treatment, levels = trt_levels),
         sampleID = fct_inorder(sampleID))

p <- ggplot(qc_for_barplot) +
  aes(x = proportion, y = sampleID, fill = status) +
  geom_col(color = "grey50") +
  scale_x_continuous(labels = scales::comma,
                     expand = expansion(mult = c(0, 0.01))) +
  scale_y_discrete(limits = rev) +
  scale_fill_brewer(palette = "Set3") +
  labs(fill = "Reads removed by", x = "Number of reads", y = "") +
  theme(panel.grid.major.y = element_blank(),
        axis.text.y = element_text(size = 9))

if(show_sample_names == FALSE) {
  p <- p +
    labs(y = "Sample") +
    theme(axis.text.y = element_blank())
}

print(p)
```

### Barplot of remaining reads -- all samples

Showing the number of remaining reads (which are ASVs at that point)
after the entire ASV inference pipeline for _all samples_, failed and passed.

```{r}
qc_for_barplot %>%
  filter(status == "(remaining)") %>%
  ggplot() +
  aes(x = proportion, y = sampleID, fill = treatment) +
  geom_col() +
  scale_x_continuous(labels = scales::comma,
                     expand = expansion(mult = c(0, 0.01))) +
  scale_y_discrete(limits = rev) +
  scale_fill_manual(values = trt_cols) +
  labs(fill = "Treatment", x = "Number of reads", y = "") +
  theme(panel.grid.major.y = element_blank(),
        axis.text.y = element_text(size = 9))
```

### Barplot of remaining reads -- passed samples

Showing the number of remaining reads (which are ASVs at that point)
after the entire ASV inference pipeline for _passed samples_ (>=1,000 reads).

```{r}
qc_for_barplot %>%
  filter(status == "(remaining)", sampleID %in% smp_pass) %>%
  ggplot() +
  aes(x = proportion, y = sampleID, fill = treatment) +
  geom_col() +
  scale_x_continuous(labels = scales::comma,
                     expand = expansion(mult = c(0, 0.01))) +
  scale_fill_manual(values = trt_cols) +
  labs(fill = "Treatment", x = "Number of reads", y = "") +
  theme(panel.grid.major.y = element_blank(),
        axis.text.y = element_text(size = 9))
```

### Barplot of remaining reads -- failed samples

Showing the number of remaining reads (which are ASVs at that point)
after the entire ASV inference pipeline for _failed samples_ (<1,000 reads).

```{r}
qc_for_barplot %>%
  filter(status == "(remaining)", ! sampleID %in% smp_pass) %>%
  ggplot() +
  aes(x = proportion, y = sampleID, fill = treatment) +
  geom_col() +
  scale_x_continuous(labels = scales::comma,
                     expand = expansion(mult = c(0, 0.01))) +
  scale_fill_manual(values = trt_cols) +
  labs(fill = "Treatment", x = "Number of reads", y = "") +
  theme(panel.grid.major.y = element_blank(),
        axis.text.y = element_text(size = 9))
```

### Mean number of reads at each step

```{r}
## Make df with proportions
qc_prop <- qc %>%
  mutate(`FASTQ filtered` = `FASTQ filtered` / Input,
         Denoised = Denoised / Input,
         `Pairs merged` = `Pairs merged` / Input,
         `Non-chimeric` = `Non-chimeric` / Input,
         `Length-filtered` = `Length-filtered` / Input,
         Input = 1)

## Get mean proportions
qc_prop_mean <- qc_prop %>% summarise_if(is.numeric, ~ round(mean(.x), 4))
qc_mean <- qc %>% summarise_if(is.numeric, ~ round(mean(.x)))

means <- data.frame(t(qc_mean), t(qc_prop_mean))
colnames(means) <- c("Mean # of reads remaining",
                     "Mean proportion of reads remaining")
row.names(means) <- c("Input", "Filtered", "Denoised", "Merged",
                      "Non-chimeric", "Length-filtered")
means %>%
  kable(format.args = list(big.mark = ",")) %>%
  kable_styling(full_width = FALSE, bootstrap_options = "striped")
```

### Full table

All numbers in the table represent the number of reads remaining at each step.

```{r}
qc %>% make_dt(big_cols = colnames(qc)[2:ncol(qc)])
```

<br>

----

## Taxonomic assignment success

```{r}
taxa <- tax_table(ps)
```

```{r}
## Function to get the proportion of ASVs assigned to taxa
qc_tax <- function(taxa, tax_levels) {
    n <- apply(taxa, 2, function(x) length(which(!is.na(x))))
    prop <- round(n / nrow(taxa), 4)
    
    tax_assign <- data.frame(n, prop) %>%
        rownames_to_column("tax_level") %>%
        mutate(tax_level = factor(tax_level, levels = tax_levels))

    return(tax_assign)
}
```

```{r}
## Create df with proportion assigned
tax_assign <- qc_tax(taxa, tax_levels = tax_levels)
```

### Barplot

```{r}
## Create barplot
ggplot(tax_assign) +
    geom_col(aes(x = tax_level, y = prop, fill = tax_level),
             color = "grey20") +
    scale_fill_brewer(palette = "Greens") +
    scale_y_continuous(limits = c(0, 1), expand = c(0, 0)) +
    labs(y = "Proportion of ASVs assigned to taxonomic level",
         x = NULL) +
    guides(fill = "none")
```

### Table

```{r}
tax_assign %>%
  dplyr::rename(`Taxonomic level` = tax_level,
                `Number assigned` = n,
                `Proportion assigned` = prop) %>%
  kable(format.args = list(big.mark = ",")) %>%
  kable_styling(full_width = FALSE, bootstrap_options = "striped")
```

<br>

----

## References
